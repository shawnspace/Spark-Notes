每一个spark程序都是由 a driver program that runs the user’s main function and executes various parallel operations on a cluster。

RDD: a collection of elements partitioned across the nodes of the cluster，可以进行并行化操作

shared variables：Spark runs a function in parallel as a set of tasks on different nodes, it ships a copy of each variable used in the function to each task
第一类：broadcast variables，which can be used to cache a value in memory on all nodes
第二类：accumulators, which are variables that are only “added” to

